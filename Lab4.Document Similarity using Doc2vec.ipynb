{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e63fcdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a31c966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=[\"I love machine learning. Its awesome.\",\n",
    "      \"I love coding in python\",\n",
    "      \"I love building chatbots\",\n",
    "      \"they chat amagingly well\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "575e602c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tagged_data=[TaggedDocument(words=word_tokenize(d.lower()),\n",
    "      tags=[str(i)]) for i,d in enumerate(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e23f6c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "#model parameters\n",
    "vec_size=20\n",
    "alpha=0.025\n",
    "\n",
    "#create model\n",
    "model=Doc2Vec(vector_size=vec_size,\n",
    "             alpha=alpha,\n",
    "             min_alpha=0.00025,\n",
    "             min_count=1,\n",
    "             dm=1)\n",
    "\n",
    "#build vocabulary\n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "#shuffle data\n",
    "tagged_data=utils.shuffle(tagged_data)\n",
    "\n",
    "#train Doc2Vec model\n",
    "model.train(tagged_data,\n",
    "           total_examples=model.corpus_count,\n",
    "           epochs=30)\n",
    "\n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8ac7352",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1_infer [ 7.2100913e-05  1.3363539e-02  5.7909283e-04 -9.7696390e-03\n",
      "  8.4970137e-03 -4.0888228e-03 -1.1952376e-03 -2.1484524e-02\n",
      "  2.0664852e-02  1.5349517e-02  9.3155040e-04 -2.1373786e-02\n",
      "  9.7855239e-04 -1.5119630e-02  1.0290420e-02 -1.7054562e-02\n",
      "  4.9189475e-05  3.8542340e-03 -2.0071367e-02 -1.0365028e-02]\n",
      "[('2', 0.32829704880714417), ('0', 0.2789109945297241), ('3', 0.21662947535514832)]\n",
      "[-0.01900733  0.01295024 -0.02856737  0.01302574  0.02925075 -0.04079853\n",
      " -0.041809   -0.05001531  0.02467139 -0.04596317  0.02918165  0.03414039\n",
      " -0.03297682 -0.02300372 -0.00649546  0.00835309 -0.00748843 -0.04271869\n",
      " -0.01833478  0.00887218]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "model=Doc2Vec.load(\"d2v.model\")\n",
    "\n",
    "#to find the vector of a document which is not in training data\n",
    "\n",
    "test_data=word_tokenize(\"I love chatbots\".lower())\n",
    "v1=model.infer_vector(test_data)\n",
    "print(\"v1_infer\",v1)\n",
    "\n",
    "#to find most similar doc using tags\n",
    "similar_doc=model.dv.most_similar('1')\n",
    "print(similar_doc)\n",
    "\n",
    "#to find vector of doc in training data using tags or\n",
    "#In other words,printing the vector of document at index 1 in training data\n",
    "\n",
    "print(model.dv[\"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6eaa95b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = [\"the house had a tiny little mouse\",\n",
    "        \"the cat saw the mouse\",\n",
    "        \"the mouse ran away from the house\",\n",
    "        \"the cat finally ate the mouse\",\n",
    "        \"the end of the mouse story\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4d56bfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tagged_docs=[TaggedDocument(words=word_tokenize(d.lower()),\n",
    "      tags=[str(i)]) for i,d in enumerate(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dfbae1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "#model parameters\n",
    "vec_size=20\n",
    "alpha=0.025\n",
    "\n",
    "#create model\n",
    "model=Doc2Vec(vector_size=vec_size,\n",
    "             alpha=alpha,\n",
    "             min_alpha=0.00025,\n",
    "             min_count=1,\n",
    "             dm=1)\n",
    "\n",
    "#build vocabulary\n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "#shuffle data\n",
    "tagged_data=utils.shuffle(tagged_data)\n",
    "\n",
    "#train Doc2Vec model\n",
    "model.train(tagged_data,\n",
    "           total_examples=model.corpus_count,\n",
    "           epochs=30)\n",
    "\n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2e93983",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1_infer [ 0.00018744  0.01340385  0.00055276 -0.00960984  0.00836213 -0.0038745\n",
      " -0.00117498 -0.02133051  0.02046019  0.01564211  0.0009592  -0.02144791\n",
      "  0.00124427 -0.0149161   0.01038323 -0.01723213  0.00018896  0.00396942\n",
      " -0.01995967 -0.01056608]\n",
      "[('2', 0.2761462330818176), ('0', -0.10477674752473831), ('3', -0.3513389229774475)]\n",
      "[-0.02673234 -0.03051322 -0.04974305  0.04260949  0.01867599  0.00057413\n",
      " -0.05004338 -0.02644612 -0.04897651  0.00912078  0.01400832  0.02368603\n",
      " -0.02264508 -0.01714981 -0.01608227 -0.04348478  0.01093464  0.04667209\n",
      " -0.0487971  -0.01683346]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "model=Doc2Vec.load(\"d2v.model\")\n",
    "\n",
    "#to find the vector of a document which is not in training data\n",
    "\n",
    "test_data=word_tokenize(\"I love chatbots\".lower())\n",
    "v1=model.infer_vector(test_data)\n",
    "print(\"v1_infer\",v1)\n",
    "\n",
    "#to find most similar doc using tags\n",
    "similar_doc=model.dv.most_similar('1')\n",
    "print(similar_doc)\n",
    "\n",
    "#to find vector of doc in training data using tags or\n",
    "#In other words,printing the vector of document at index 1 in training data\n",
    "\n",
    "print(model.dv[\"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33522849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97255e2f-5c53-4902-b760-1ce0a7aec056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
